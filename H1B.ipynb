{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMaCfQX2RGHp",
        "outputId": "18ee71db-da31-4eb2-f45e-5c6ec3c34dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNT0UUGKTdRh",
        "outputId": "03d87a1e-ea45-4e65-cecc-bb1f19555b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'\n",
            "'Document from Rosie'\n",
            "'FeeReceipt (2)_copy.pdf'\n",
            "'goresume-compressed (1).pdf'\n",
            "'goresume-compressed (2).pdf'\n",
            " goresume-compressed.pdf\n",
            " h1b_data\n",
            " IMG-20250306-WA0001.jpg\n",
            "'rohg (1).jpeg'\n",
            " rohg.jpeg\n",
            "'roja certificate (1).pdf'\n",
            "'Screenshot_20250227_181303_PDF Scanner (1).jpg'\n",
            "'Screenshot_20250227_181303_PDF Scanner.jpg'\n",
            " Screenshot_20250324_164842_Gallery.jpg\n",
            " Screenshot_20250326_183620_PhonePe.jpg\n",
            "'Screenshot_20250411_192253_Google (1).jpg'\n",
            "'Screenshot_20250411_192253_Google (2).jpg'\n",
            " Screenshot_20250411_192253_Google.jpg\n",
            " Screenshot_20250521_202516_PhonePe.jpg\n",
            "'Screenshot 2025-08-17 130547.png'\n",
            " Screenshot_20251003_202117_Gallery.jpg\n",
            "'Weather App - PM Accelerator - Google Chrome 2025-11-16 00-11-06.mp4'\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP3hX7eQT9GU",
        "outputId": "8173e6d0-a5ab-456e-e616-864569191e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LCA_Disclosure_Data_FY2024_Q4.xlsx  'LCA_Disclosure_Data_FY2026_Q1 (1).xlsx'\n",
            " LCA_Disclosure_Data_FY2025_Q4.xlsx\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/h1b_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZLhHkzwUM7P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file1 = \"/content/drive/MyDrive/h1b_data/LCA_Disclosure_Data_FY2024_Q4.xlsx\"\n",
        "file2 = \"/content/drive/MyDrive/h1b_data/LCA_Disclosure_Data_FY2025_Q4.xlsx\"\n",
        "file3 = \"/content/drive/MyDrive/h1b_data/LCA_Disclosure_Data_FY2026_Q1 (1).xlsx\"\n",
        "\n",
        "df1 = pd.read_excel(file1)\n",
        "df2 = pd.read_excel(file2)\n",
        "df3 = pd.read_excel(file3)\n",
        "\n",
        "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "print(\"Total rows:\", combined_df.shape[0])\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-bSVs6n1UkQy",
        "outputId": "1ecd1039-d2af-45d5-cdfc-cb8eaf3b4e93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VISA_CLASS</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>H-1B</th>\n",
              "      <td>312017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E-3 Australian</th>\n",
              "      <td>7827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H-1B1 Chile</th>\n",
              "      <td>1582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H-1B1 Singapore</th>\n",
              "      <td>1171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "VISA_CLASS\n",
              "H-1B               312017\n",
              "E-3 Australian       7827\n",
              "H-1B1 Chile          1582\n",
              "H-1B1 Singapore      1171\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df['VISA_CLASS'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O9bi5WD0Apl",
        "outputId": "d8400020-778f-46dd-fce6-a2c0ca5eaa43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H1B rows: 312017\n"
          ]
        }
      ],
      "source": [
        "h1b_df = combined_df[combined_df['VISA_CLASS'] == 'H-1B']\n",
        "\n",
        "print(\"H1B rows:\", h1b_df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "W3nLKCWi0SRt",
        "outputId": "706bf3cd-ca2e-493c-a1cd-0696eadcaeb8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CASE_STATUS</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Certified</th>\n",
              "      <td>282098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Certified - Withdrawn</th>\n",
              "      <td>23355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Withdrawn</th>\n",
              "      <td>4931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Denied</th>\n",
              "      <td>1633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "CASE_STATUS\n",
              "Certified                282098\n",
              "Certified - Withdrawn     23355\n",
              "Withdrawn                  4931\n",
              "Denied                     1633\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h1b_df['CASE_STATUS'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxWvj6zt0i52",
        "outputId": "8bfe5c0f-9f3a-45a9-9acd-7f4c93249da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns kept: Index(['CASE_STATUS', 'JOB_TITLE', 'SOC_CODE', 'SOC_TITLE',\n",
            "       'FULL_TIME_POSITION', 'PREVAILING_WAGE', 'WAGE_UNIT_OF_PAY',\n",
            "       'WORKSITE_STATE', 'EMPLOYER_NAME', 'SUPPORT_H1B'],\n",
            "      dtype='object')\n",
            "New shape: (312017, 10)\n"
          ]
        }
      ],
      "source": [
        "useful_columns = [\n",
        "    'CASE_STATUS',\n",
        "    'JOB_TITLE',\n",
        "    'SOC_CODE',\n",
        "    'SOC_TITLE',\n",
        "    'FULL_TIME_POSITION',\n",
        "    'PREVAILING_WAGE',\n",
        "    'WAGE_UNIT_OF_PAY',\n",
        "    'WORKSITE_STATE',\n",
        "    'EMPLOYER_NAME',\n",
        "    'SUPPORT_H1B'\n",
        "]\n",
        "\n",
        "h1b_df = h1b_df[useful_columns]\n",
        "\n",
        "print(\"Columns kept:\", h1b_df.columns)\n",
        "print(\"New shape:\", h1b_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlGWz42l1Xfs",
        "outputId": "720eed02-1788-4190-f909-8984a1e396c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CASE_STATUS\n",
            "Certified    282098\n",
            "Denied         1633\n",
            "Name: count, dtype: int64\n",
            "New shape: (283731, 10)\n"
          ]
        }
      ],
      "source": [
        "h1b_df = h1b_df[h1b_df['CASE_STATUS'].isin(['Certified', 'Denied'])]\n",
        "\n",
        "print(h1b_df['CASE_STATUS'].value_counts())\n",
        "print(\"New shape:\", h1b_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUGL3gFH1geZ",
        "outputId": "e7edd2ec-5882-4db7-8cd6-f33a698263c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  CASE_STATUS  TARGET\n",
            "0   Certified       1\n",
            "1   Certified       1\n",
            "2   Certified       1\n",
            "3   Certified       1\n",
            "4   Certified       1\n"
          ]
        }
      ],
      "source": [
        "h1b_df['TARGET'] = h1b_df['CASE_STATUS'].map({\n",
        "    'Certified': 1,\n",
        "    'Denied': 0\n",
        "})\n",
        "\n",
        "print(h1b_df[['CASE_STATUS', 'TARGET']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAKWUruJ1uF7",
        "outputId": "d271e511-5fba-47a1-e3fd-1b092f4444b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TARGET\n",
            "1    1633\n",
            "0    1633\n",
            "Name: count, dtype: int64\n",
            "New shape: (3266, 11)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate classes\n",
        "certified = h1b_df[h1b_df['TARGET'] == 1]\n",
        "denied = h1b_df[h1b_df['TARGET'] == 0]\n",
        "\n",
        "# Downsample Certified\n",
        "certified_downsampled = resample(\n",
        "    certified,\n",
        "    replace=False,\n",
        "    n_samples=len(denied),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine\n",
        "balanced_df = pd.concat([certified_downsampled, denied])\n",
        "\n",
        "print(balanced_df['TARGET'].value_counts())\n",
        "print(\"New shape:\", balanced_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi-IzWqR13pG",
        "outputId": "d3538373-5170-40f3-df81-abc954292ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained successfully üöÄ\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Separate features and target\n",
        "X = balanced_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = balanced_df['TARGET']\n",
        "\n",
        "# Combine text columns\n",
        "X['TEXT'] = X['JOB_TITLE'].astype(str) + \" \" + X['SOC_TITLE'].astype(str)\n",
        "\n",
        "# Define columns\n",
        "text_col = 'TEXT'\n",
        "categorical_cols = ['WORKSITE_STATE', 'SUPPORT_H1B', 'FULL_TIME_POSITION']\n",
        "numeric_cols = ['PREVAILING_WAGE']\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', TfidfVectorizer(max_features=300), text_col),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('num', 'passthrough', numeric_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Full pipeline\n",
        "model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42))\n",
        "])\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK7g-3KG28T1",
        "outputId": "ee367a37-b72b-4bf3-aab0-644ce7915f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHpOLkvJ3W1j",
        "outputId": "e4457e69-6045-4ce7-d209-d8c08cf4de1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Professional XGBoost model trained successfully üöÄ\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Separate features & target\n",
        "X = balanced_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = balanced_df['TARGET']\n",
        "\n",
        "# Combine text columns\n",
        "X['TEXT'] = X['JOB_TITLE'].astype(str) + \" \" + X['SOC_TITLE'].astype(str)\n",
        "\n",
        "# Define columns\n",
        "text_col = 'TEXT'\n",
        "categorical_cols = ['WORKSITE_STATE', 'SUPPORT_H1B', 'FULL_TIME_POSITION']\n",
        "numeric_cols = ['PREVAILING_WAGE']\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', TfidfVectorizer(max_features=300), text_col),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('num', 'passthrough', numeric_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Professional XGBoost model\n",
        "xgb_model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Professional XGBoost model trained successfully üöÄ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CFVlpb73eer",
        "outputId": "7dc05a3a-ba8d-40dd-b398-1af6bd5d3598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability of Certified: 0.57284665\n"
          ]
        }
      ],
      "source": [
        "sample = X_test.iloc[[0]]\n",
        "prob = xgb_model.predict_proba(sample)\n",
        "\n",
        "print(\"Probability of Certified:\", prob[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsLnBeIC3kcz"
      },
      "outputs": [],
      "source": [
        "X = h1b_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = h1b_df['TARGET']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibkLjXAy395Z",
        "outputId": "aa208874-9cbc-42b5-9d79-2f9d2b4b1a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scale pos weight: 0.005788768442172579\n"
          ]
        }
      ],
      "source": [
        "neg = sum(y == 0)\n",
        "pos = sum(y == 1)\n",
        "\n",
        "scale_weight = neg / pos\n",
        "print(\"Scale pos weight:\", scale_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHtdXPMt4Qym",
        "outputId": "77f71cab-2b47-4d54-b40e-f60d3d0ce8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrNF2_5e5iwm",
        "outputId": "a6794421-499b-49c8-9088-36e2709a4592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scale_pos_weight: 0.005788768442172579\n",
            "Base model trained successfully üöÄ\n",
            "Calibrated model trained successfully üî•\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       327\n",
            "           1       0.99      1.00      1.00     56420\n",
            "\n",
            "    accuracy                           0.99     56747\n",
            "   macro avg       0.50      0.50      0.50     56747\n",
            "weighted avg       0.99      0.99      0.99     56747\n",
            "\n",
            "ROC-AUC Score: 0.886982840578579\n",
            "Model saved successfully ‚úÖ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "# Use full filtered dataset (Certified + Denied only)\n",
        "X = h1b_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = h1b_df['TARGET']\n",
        "\n",
        "# Create combined text column\n",
        "X['TEXT'] = X['JOB_TITLE'].astype(str) + \" \" + X['SOC_TITLE'].astype(str)\n",
        "\n",
        "# Calculate imbalance ratio\n",
        "neg = sum(y == 0)\n",
        "pos = sum(y == 1)\n",
        "\n",
        "scale_weight = neg / pos\n",
        "print(\"Scale_pos_weight:\", scale_weight)\n",
        "text_col = 'TEXT'\n",
        "categorical_cols = ['WORKSITE_STATE', 'SUPPORT_H1B', 'FULL_TIME_POSITION']\n",
        "numeric_cols = ['PREVAILING_WAGE']\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', TfidfVectorizer(max_features=500), text_col),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('num', 'passthrough', numeric_cols)\n",
        "    ]\n",
        ")\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_weight,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', xgb)\n",
        "])\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Base model trained successfully üöÄ\")\n",
        "calibrated_model = CalibratedClassifierCV(model, method='sigmoid', cv=3)\n",
        "\n",
        "calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Calibrated model trained successfully üî•\")\n",
        "y_pred = calibrated_model.predict(X_test)\n",
        "y_prob = calibrated_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "joblib.dump(calibrated_model, \"h1b_approval_model.pkl\")\n",
        "\n",
        "print(\"Model saved successfully ‚úÖ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmdbobPj6DHS"
      },
      "outputs": [],
      "source": [
        "y_prob = calibrated_model.predict_proba(X_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygPT6GUZ7RTc",
        "outputId": "5814043e-56d8-4ac8-846e-51e8f6334aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Threshold: 0.8099999999999996\n",
            "Best F1 Score: 0.9977974152800998\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    score = f1_score(y_test, y_pred_temp)\n",
        "\n",
        "    if score > best_f1:\n",
        "        best_f1 = score\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best F1 Score:\", best_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxw6_XW47qwp",
        "outputId": "801cf167-1da1-4d42-de2f-39d1a9952e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.30      0.44       327\n",
            "           1       1.00      1.00      1.00     56420\n",
            "\n",
            "    accuracy                           1.00     56747\n",
            "   macro avg       0.91      0.65      0.72     56747\n",
            "weighted avg       1.00      1.00      0.99     56747\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcJ-W3nkAEJB",
        "outputId": "c958a6fb-3436-40e7-e1b8-dbbf57f84d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorical columns: Index(['CASE_STATUS', 'JOB_TITLE', 'SOC_CODE', 'SOC_TITLE',\n",
            "       'FULL_TIME_POSITION', 'WAGE_UNIT_OF_PAY', 'WORKSITE_STATE',\n",
            "       'EMPLOYER_NAME', 'SUPPORT_H1B'],\n",
            "      dtype='object')\n",
            "Encoding completed ‚úÖ\n",
            "Shape after encoding: (3266, 4266)\n",
            "Column names cleaned ‚úÖ\n",
            "Scale_pos_weight: 1.0\n",
            "Model trained successfully üöÄ\n",
            "ROC-AUC Score: 1.0\n",
            "Best Threshold: 0.1\n",
            "Best Denied Recall: 1.0\n",
            "\n",
            "Final Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       327\n",
            "           1       1.00      1.00      1.00       327\n",
            "\n",
            "    accuracy                           1.00       654\n",
            "   macro avg       1.00      1.00      1.00       654\n",
            "weighted avg       1.00      1.00      1.00       654\n",
            "\n",
            "Model saved successfully ‚úÖ\n",
            "\n",
            "Pipeline ready for deployment üéØ\n"
          ]
        }
      ],
      "source": [
        "# ======================================================\n",
        "# FINAL PROFESSIONAL H1B MODEL\n",
        "# Encoding + Column Cleaning + Imbalance + Threshold\n",
        "# ======================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, recall_score\n",
        "import joblib\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 1Ô∏è‚É£ Prepare Features & Target\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X = balanced_df.drop(columns=[\"TARGET\"])\n",
        "y = balanced_df[\"TARGET\"]\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 2Ô∏è‚É£ Encode Categorical Features\n",
        "# ------------------------------------------------------\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"Encoding completed ‚úÖ\")\n",
        "print(\"Shape after encoding:\", X.shape)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 3Ô∏è‚É£ Clean Column Names (VERY IMPORTANT FIX)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X.columns = (\n",
        "    X.columns\n",
        "    .str.replace('[', '', regex=False)\n",
        "    .str.replace(']', '', regex=False)\n",
        "    .str.replace('<', '', regex=False)\n",
        "    .str.replace('>', '', regex=False)\n",
        "    .str.replace(' ', '_', regex=False)\n",
        ")\n",
        "\n",
        "print(\"Column names cleaned ‚úÖ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 4Ô∏è‚É£ Train-Test Split\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 5Ô∏è‚É£ Handle Imbalance\n",
        "# ------------------------------------------------------\n",
        "\n",
        "neg = sum(y_train == 0)\n",
        "pos = sum(y_train == 1)\n",
        "\n",
        "scale_pos_weight = neg / pos\n",
        "print(\"Scale_pos_weight:\", scale_pos_weight)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 6Ô∏è‚É£ Train XGBoost\n",
        "# ------------------------------------------------------\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 7Ô∏è‚É£ Probabilities & ROC\n",
        "# ------------------------------------------------------\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 8Ô∏è‚É£ Threshold Optimization (Denied Recall Focus)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_recall = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    recall_denied = recall_score(y_test, y_pred_temp, pos_label=0)\n",
        "\n",
        "    if recall_denied > best_recall:\n",
        "        best_recall = recall_denied\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best Denied Recall:\", best_recall)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 9Ô∏è‚É£ Final Evaluation\n",
        "# ------------------------------------------------------\n",
        "\n",
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\nFinal Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üîü Save Model\n",
        "# ------------------------------------------------------\n",
        "\n",
        "joblib.dump(model, \"h1b_professional_model.pkl\")\n",
        "print(\"Model saved successfully ‚úÖ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Personalized Prediction Function\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def predict_h1b(input_df):\n",
        "    input_df = pd.get_dummies(input_df)\n",
        "    input_df = input_df.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    prob = model.predict_proba(input_df)[:,1][0]\n",
        "    prediction = 1 if prob >= best_threshold else 0\n",
        "\n",
        "    return {\n",
        "        \"Probability_Certified\": round(float(prob), 4),\n",
        "        \"Prediction\": \"Certified\" if prediction == 1 else \"Denied\"\n",
        "    }\n",
        "\n",
        "print(\"\\nPipeline ready for deployment üéØ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eynfdgheAsM_"
      },
      "outputs": [],
      "source": [
        "[1]\n",
        "34s\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "Mounted at /content/drive\n",
        "\n",
        "[2]\n",
        "0s\n",
        "!ls /content/drive/MyDrive\n",
        "'Colab Notebooks'\n",
        "'Document from Rosie'\n",
        "'FeeReceipt (2)_copy.pdf'\n",
        "'goresume-compressed (1).pdf'\n",
        "'goresume-compressed (2).pdf'\n",
        " goresume-compressed.pdf\n",
        " h1b_data\n",
        " IMG-20250306-WA0001.jpg\n",
        "'rohg (1).jpeg'\n",
        " rohg.jpeg\n",
        "'roja certificate (1).pdf'\n",
        "'Screenshot_20250227_181303_PDF Scanner (1).jpg'\n",
        "'Screenshot_20250227_181303_PDF Scanner.jpg'\n",
        " Screenshot_20250324_164842_Gallery.jpg\n",
        " Screenshot_20250326_183620_PhonePe.jpg\n",
        "'Screenshot_20250411_192253_Google (1).jpg'\n",
        "'Screenshot_20250411_192253_Google (2).jpg'\n",
        " Screenshot_20250411_192253_Google.jpg\n",
        " Screenshot_20250521_202516_PhonePe.jpg\n",
        "'Screenshot 2025-08-17 130547.png'\n",
        " Screenshot_20251003_202117_Gallery.jpg\n",
        "'Weather App - PM Accelerator - Google Chrome 2025-11-16 00-11-06.mp4'\n",
        "\n",
        "[3]\n",
        "0s\n",
        "!ls /content/drive/MyDrive/h1b_data\n",
        " LCA_Disclosure_Data_FY2024_Q4.xlsx  'LCA_Disclosure_Data_FY2026_Q1 (1).xlsx'\n",
        " LCA_Disclosure_Data_FY2025_Q4.xlsx\n",
        "\n",
        "[5]\n",
        "import pandas as pd\n",
        "\n",
        "file1 = \"/content/drive/MyDrive/h1b_data/LCA_Disclosure_Data_FY2024_Q4.xlsx\"\n",
        "file2 = \"/content/drive/MyDrive/h1b_data/LCA_Disclosure_Data_FY2025_Q4.xlsx\"\n",
        "file3 = \"/content/drive/MyDrive/h1b_data/LCA_Disclosure_Data_FY2026_Q1 (1).xlsx\"\n",
        "\n",
        "df1 = pd.read_excel(file1)\n",
        "df2 = pd.read_excel(file2)\n",
        "df3 = pd.read_excel(file3)\n",
        "\n",
        "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "print(\"Total rows:\", combined_df.shape[0])\n",
        "combined_df.head()\n",
        "\n",
        "\n",
        "[6]\n",
        "0s\n",
        "combined_df['VISA_CLASS'].value_counts()\n",
        "\n",
        "\n",
        "[7]\n",
        "1s\n",
        "h1b_df = combined_df[combined_df['VISA_CLASS'] == 'H-1B']\n",
        "\n",
        "print(\"H1B rows:\", h1b_df.shape[0])\n",
        "H1B rows: 312017\n",
        "\n",
        "[8]\n",
        "0s\n",
        "h1b_df['CASE_STATUS'].value_counts()\n",
        "\n",
        "\n",
        "[9]\n",
        "0s\n",
        "useful_columns = [\n",
        "    'CASE_STATUS',\n",
        "    'JOB_TITLE',\n",
        "    'SOC_CODE',\n",
        "    'SOC_TITLE',\n",
        "    'FULL_TIME_POSITION',\n",
        "    'PREVAILING_WAGE',\n",
        "    'WAGE_UNIT_OF_PAY',\n",
        "    'WORKSITE_STATE',\n",
        "    'EMPLOYER_NAME',\n",
        "    'SUPPORT_H1B'\n",
        "]\n",
        "\n",
        "h1b_df = h1b_df[useful_columns]\n",
        "\n",
        "print(\"Columns kept:\", h1b_df.columns)\n",
        "print(\"New shape:\", h1b_df.shape)\n",
        "Columns kept: Index(['CASE_STATUS', 'JOB_TITLE', 'SOC_CODE', 'SOC_TITLE',\n",
        "       'FULL_TIME_POSITION', 'PREVAILING_WAGE', 'WAGE_UNIT_OF_PAY',\n",
        "       'WORKSITE_STATE', 'EMPLOYER_NAME', 'SUPPORT_H1B'],\n",
        "      dtype='object')\n",
        "New shape: (312017, 10)\n",
        "\n",
        "[10]\n",
        "0s\n",
        "h1b_df = h1b_df[h1b_df['CASE_STATUS'].isin(['Certified', 'Denied'])]\n",
        "\n",
        "print(h1b_df['CASE_STATUS'].value_counts())\n",
        "print(\"New shape:\", h1b_df.shape)\n",
        "CASE_STATUS\n",
        "Certified    282098\n",
        "Denied         1633\n",
        "Name: count, dtype: int64\n",
        "New shape: (283731, 10)\n",
        "\n",
        "[11]\n",
        "0s\n",
        "h1b_df['TARGET'] = h1b_df['CASE_STATUS'].map({\n",
        "    'Certified': 1,\n",
        "    'Denied': 0\n",
        "})\n",
        "\n",
        "print(h1b_df[['CASE_STATUS', 'TARGET']].head())\n",
        "  CASE_STATUS  TARGET\n",
        "0   Certified       1\n",
        "1   Certified       1\n",
        "2   Certified       1\n",
        "3   Certified       1\n",
        "4   Certified       1\n",
        "\n",
        "[12]\n",
        "2s\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate classes\n",
        "certified = h1b_df[h1b_df['TARGET'] == 1]\n",
        "denied = h1b_df[h1b_df['TARGET'] == 0]\n",
        "\n",
        "# Downsample Certified\n",
        "certified_downsampled = resample(\n",
        "    certified,\n",
        "    replace=False,\n",
        "    n_samples=len(denied),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine\n",
        "balanced_df = pd.concat([certified_downsampled, denied])\n",
        "\n",
        "print(balanced_df['TARGET'].value_counts())\n",
        "print(\"New shape:\", balanced_df.shape)\n",
        "TARGET\n",
        "1    1633\n",
        "0    1633\n",
        "Name: count, dtype: int64\n",
        "New shape: (3266, 11)\n",
        "\n",
        "[13]\n",
        "7s\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Separate features and target\n",
        "X = balanced_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = balanced_df['TARGET']\n",
        "\n",
        "# Combine text columns\n",
        "X['TEXT'] = X['JOB_TITLE'].astype(str) + \" \" + X['SOC_TITLE'].astype(str)\n",
        "\n",
        "# Define columns\n",
        "text_col = 'TEXT'\n",
        "categorical_cols = ['WORKSITE_STATE', 'SUPPORT_H1B', 'FULL_TIME_POSITION']\n",
        "numeric_cols = ['PREVAILING_WAGE']\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', TfidfVectorizer(max_features=300), text_col),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('num', 'passthrough', numeric_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Full pipeline\n",
        "model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42))\n",
        "])\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")\n",
        "Model trained successfully üöÄ\n",
        "\n",
        "[14]\n",
        "8s\n",
        "!pip install xgboost\n",
        "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
        "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
        "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
        "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
        "\n",
        "[15]\n",
        "7s\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Separate features & target\n",
        "X = balanced_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = balanced_df['TARGET']\n",
        "\n",
        "# Combine text columns\n",
        "X['TEXT'] = X['JOB_TITLE'].astype(str) + \" \" + X['SOC_TITLE'].astype(str)\n",
        "\n",
        "# Define columns\n",
        "text_col = 'TEXT'\n",
        "categorical_cols = ['WORKSITE_STATE', 'SUPPORT_H1B', 'FULL_TIME_POSITION']\n",
        "numeric_cols = ['PREVAILING_WAGE']\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', TfidfVectorizer(max_features=300), text_col),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('num', 'passthrough', numeric_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Professional XGBoost model\n",
        "xgb_model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Professional XGBoost model trained successfully üöÄ\")\n",
        "Professional XGBoost model trained successfully üöÄ\n",
        "\n",
        "[16]\n",
        "0s\n",
        "sample = X_test.iloc[[0]]\n",
        "prob = xgb_model.predict_proba(sample)\n",
        "\n",
        "print(\"Probability of Certified:\", prob[0][1])\n",
        "Probability of Certified: 0.57284665\n",
        "\n",
        "[17]\n",
        "0s\n",
        "X = h1b_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = h1b_df['TARGET']\n",
        "\n",
        "[18]\n",
        "0s\n",
        "neg = sum(y == 0)\n",
        "pos = sum(y == 1)\n",
        "\n",
        "scale_weight = neg / pos\n",
        "print(\"Scale pos weight:\", scale_weight)\n",
        "Scale pos weight: 0.005788768442172579\n",
        "\n",
        "[20]\n",
        "8s\n",
        "!pip install xgboost\n",
        "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
        "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
        "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
        "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
        "\n",
        "[21]\n",
        "1m\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "# Use full filtered dataset (Certified + Denied only)\n",
        "X = h1b_df.drop(['CASE_STATUS', 'TARGET'], axis=1)\n",
        "y = h1b_df['TARGET']\n",
        "\n",
        "# Create combined text column\n",
        "X['TEXT'] = X['JOB_TITLE'].astype(str) + \" \" + X['SOC_TITLE'].astype(str)\n",
        "\n",
        "# Calculate imbalance ratio\n",
        "neg = sum(y == 0)\n",
        "pos = sum(y == 1)\n",
        "\n",
        "scale_weight = neg / pos\n",
        "print(\"Scale_pos_weight:\", scale_weight)\n",
        "text_col = 'TEXT'\n",
        "categorical_cols = ['WORKSITE_STATE', 'SUPPORT_H1B', 'FULL_TIME_POSITION']\n",
        "numeric_cols = ['PREVAILING_WAGE']\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', TfidfVectorizer(max_features=500), text_col),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('num', 'passthrough', numeric_cols)\n",
        "    ]\n",
        ")\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_weight,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', xgb)\n",
        "])\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Base model trained successfully üöÄ\")\n",
        "calibrated_model = CalibratedClassifierCV(model, method='sigmoid', cv=3)\n",
        "\n",
        "calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Calibrated model trained successfully üî•\")\n",
        "y_pred = calibrated_model.predict(X_test)\n",
        "y_prob = calibrated_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "joblib.dump(calibrated_model, \"h1b_approval_model.pkl\")\n",
        "\n",
        "print(\"Model saved successfully ‚úÖ\")\n",
        "Scale_pos_weight: 0.005788768442172579\n",
        "Base model trained successfully üöÄ\n",
        "Calibrated model trained successfully üî•\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.00      0.00      0.00       327\n",
        "           1       0.99      1.00      1.00     56420\n",
        "\n",
        "    accuracy                           0.99     56747\n",
        "   macro avg       0.50      0.50      0.50     56747\n",
        "weighted avg       0.99      0.99      0.99     56747\n",
        "\n",
        "ROC-AUC Score: 0.886982840578579\n",
        "Model saved successfully ‚úÖ\n",
        "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
        "\n",
        "[22]\n",
        "9s\n",
        "y_prob = calibrated_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "[23]\n",
        "0s\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    score = f1_score(y_test, y_pred_temp)\n",
        "\n",
        "    if score > best_f1:\n",
        "        best_f1 = score\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best F1 Score:\", best_f1)\n",
        "Best Threshold: 0.8099999999999996\n",
        "Best F1 Score: 0.9977974152800998\n",
        "\n",
        "[24]\n",
        "0s\n",
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.83      0.30      0.44       327\n",
        "           1       1.00      1.00      1.00     56420\n",
        "\n",
        "    accuracy                           1.00     56747\n",
        "   macro avg       0.91      0.65      0.72     56747\n",
        "weighted avg       1.00      1.00      0.99     56747\n",
        "\n",
        "\n",
        "[25]\n",
        "0s\n",
        "# ================================\n",
        "# PROFESSIONAL H1B APPROVAL MODEL\n",
        "# Imbalance Handling + Threshold Tuning + Personalized Prediction\n",
        "# ================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, recall_score\n",
        "import joblib\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Prepare Features & Target\n",
        "# -------------------------------\n",
        "\n",
        "# TARGET already created as:\n",
        "# Certified = 1\n",
        "# Denied = 0\n",
        "\n",
        "X = balanced_df.drop(columns=[\"TARGET\"])\n",
        "y = balanced_df[\"TARGET\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Handle Class Imbalance\n",
        "# -------------------------------\n",
        "\n",
        "neg = sum(y_train == 0)   # Denied\n",
        "pos = sum(y_train == 1)   # Certified\n",
        "\n",
        "scale_pos_weight = neg / pos\n",
        "\n",
        "print(\"Scale_pos_weight:\", scale_pos_weight)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Train XGBoost Model\n",
        "# -------------------------------\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ Get Probabilities\n",
        "# -------------------------------\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Threshold Optimization (Denied Recall Focus)\n",
        "# -------------------------------\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_recall = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    recall_denied = recall_score(y_test, y_pred_temp, pos_label=0)\n",
        "\n",
        "    if recall_denied > best_recall:\n",
        "        best_recall = recall_denied\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best Denied Recall:\", best_recall)\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Final Evaluation\n",
        "# -------------------------------\n",
        "\n",
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\nFinal Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# -------------------------------\n",
        "# 7Ô∏è‚É£ Save Model\n",
        "# -------------------------------\n",
        "\n",
        "joblib.dump(model, \"h1b_professional_model.pkl\")\n",
        "\n",
        "print(\"Model saved successfully ‚úÖ\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8Ô∏è‚É£ Personalized Prediction Function\n",
        "# -------------------------------\n",
        "\n",
        "def predict_h1b(input_df):\n",
        "    prob = model.predict_proba(input_df)[:,1][0]\n",
        "    prediction = 1 if prob >= best_threshold else 0\n",
        "\n",
        "    return {\n",
        "        \"Probability_Certified\": round(float(prob), 4),\n",
        "        \"Prediction\": \"Certified\" if prediction == 1 else \"Denied\"\n",
        "    }\n",
        "\n",
        "print(\"\\nPipeline ready for deployment üéØ\")\n",
        "\n",
        "Next steps:\n",
        "\n",
        "[26]\n",
        "2s\n",
        "# ======================================================\n",
        "# PROFESSIONAL H1B MODEL (WITH PROPER ENCODING FIX)\n",
        "# ======================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, recall_score\n",
        "import joblib\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 1Ô∏è‚É£ Prepare Features & Target\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X = balanced_df.drop(columns=[\"TARGET\"])\n",
        "y = balanced_df[\"TARGET\"]\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 2Ô∏è‚É£ ENCODE CATEGORICAL FEATURES  üî• (FIXED PART)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"Encoding completed ‚úÖ\")\n",
        "print(\"New shape after encoding:\", X.shape)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 3Ô∏è‚É£ Train-Test Split\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 4Ô∏è‚É£ Handle Class Imbalance\n",
        "# ------------------------------------------------------\n",
        "\n",
        "neg = sum(y_train == 0)\n",
        "pos = sum(y_train == 1)\n",
        "\n",
        "scale_pos_weight = neg / pos\n",
        "print(\"Scale_pos_weight:\", scale_pos_weight)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 5Ô∏è‚É£ Train XGBoost Model\n",
        "# ------------------------------------------------------\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 6Ô∏è‚É£ Get Probabilities\n",
        "# ------------------------------------------------------\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 7Ô∏è‚É£ Threshold Optimization (Denied Recall Focus)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_recall = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    recall_denied = recall_score(y_test, y_pred_temp, pos_label=0)\n",
        "\n",
        "    if recall_denied > best_recall:\n",
        "        best_recall = recall_denied\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best Denied Recall:\", best_recall)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 8Ô∏è‚É£ Final Evaluation\n",
        "# ------------------------------------------------------\n",
        "\n",
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\nFinal Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 9Ô∏è‚É£ Save Model\n",
        "# ------------------------------------------------------\n",
        "\n",
        "joblib.dump(model, \"h1b_professional_model.pkl\")\n",
        "\n",
        "print(\"Model saved successfully ‚úÖ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üîü Personalized Prediction Function\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def predict_h1b(input_df):\n",
        "    input_df = pd.get_dummies(input_df)\n",
        "    input_df = input_df.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    prob = model.predict_proba(input_df)[:,1][0]\n",
        "    prediction = 1 if prob >= best_threshold else 0\n",
        "\n",
        "    return {\n",
        "        \"Probability_Certified\": round(float(prob), 4),\n",
        "        \"Prediction\": \"Certified\" if prediction == 1 else \"Denied\"\n",
        "    }\n",
        "\n",
        "print(\"\\nPipeline ready for deployment üéØ\")\n",
        "\n",
        "Next steps:\n",
        "\n",
        "[27]\n",
        "25s\n",
        "    }\n",
        "\n",
        "print(\"\\nPipeline ready for deployment üéØ\")\n",
        "Categorical columns: Index(['CASE_STATUS', 'JOB_TITLE', 'SOC_CODE', 'SOC_TITLE',\n",
        "       'FULL_TIME_POSITION', 'WAGE_UNIT_OF_PAY', 'WORKSITE_STATE',\n",
        "       'EMPLOYER_NAME', 'SUPPORT_H1B'],\n",
        "      dtype='object')\n",
        "Encoding completed ‚úÖ\n",
        "Shape after encoding: (3266, 4266)\n",
        "Column names cleaned ‚úÖ\n",
        "Scale_pos_weight: 1.0\n",
        "Model trained successfully üöÄ\n",
        "ROC-AUC Score: 1.0\n",
        "Best Threshold: 0.1\n",
        "Best Denied Recall: 1.0\n",
        "\n",
        "Final Classification Report:\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00       327\n",
        "           1       1.00      1.00      1.00       327\n",
        "\n",
        "    accuracy                           1.00       654\n",
        "   macro avg       1.00      1.00      1.00       654\n",
        "weighted avg       1.00      1.00      1.00       654\n",
        "\n",
        "Model saved successfully ‚úÖ\n",
        "\n",
        "Pipeline ready for deployment üéØ\n",
        "\n",
        "[ ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBs60ukgBgeC"
      },
      "outputs": [],
      "source": [
        "# ======================================================\n",
        "# FINAL PROFESSIONAL H1B MODEL (LEAKAGE FIXED)\n",
        "# Encoding + Column Cleaning + Imbalance + Threshold\n",
        "# ======================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, recall_score\n",
        "import joblib\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 1Ô∏è‚É£ Prepare Features & Target (REMOVE LEAKAGE)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# IMPORTANT: Remove TARGET and CASE_STATUS\n",
        "X = balanced_df.drop(columns=[\"TARGET\", \"CASE_STATUS\"])\n",
        "y = balanced_df[\"TARGET\"]\n",
        "\n",
        "print(\"Leakage check ‚Üí CASE_STATUS in X?:\", \"CASE_STATUS\" in X.columns)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 2Ô∏è‚É£ Encode Categorical Features\n",
        "# ------------------------------------------------------\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"Encoding completed ‚úÖ\")\n",
        "print(\"Shape after encoding:\", X.shape)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 3Ô∏è‚É£ Clean Column Names (XGBoost Safe)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X.columns = (\n",
        "    X.columns\n",
        "    .str.replace('[', '', regex=False)\n",
        "    .str.replace(']', '', regex=False)\n",
        "    .str.replace('<', '', regex=False)\n",
        "    .str.replace('>', '', regex=False)\n",
        "    .str.replace(' ', '_', regex=False)\n",
        ")\n",
        "\n",
        "print(\"Column names cleaned ‚úÖ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 4Ô∏è‚É£ Train-Test Split\n",
        "# ------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 5Ô∏è‚É£ Handle Imbalance\n",
        "# ------------------------------------------------------\n",
        "\n",
        "neg = sum(y_train == 0)\n",
        "pos = sum(y_train == 1)\n",
        "\n",
        "scale_pos_weight = neg / pos\n",
        "print(\"Scale_pos_weight:\", scale_pos_weight)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 6Ô∏è‚É£ Train XGBoost Model\n",
        "# ------------------------------------------------------\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 7Ô∏è‚É£ Evaluate ROC\n",
        "# ------------------------------------------------------\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 8Ô∏è‚É£ Threshold Optimization (Focus: Denied Recall)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "thresholds = np.arange(0.1, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_recall = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    recall_denied = recall_score(y_test, y_pred_temp, pos_label=0)\n",
        "\n",
        "    if recall_denied > best_recall:\n",
        "        best_recall = recall_denied\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best Denied Recall:\", best_recall)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 9Ô∏è‚É£ Final Evaluation\n",
        "# ------------------------------------------------------\n",
        "\n",
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\nFinal Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üîü Save Model\n",
        "# ------------------------------------------------------\n",
        "\n",
        "joblib.dump(model, \"h1b_professional_model.pkl\")\n",
        "print(\"Model saved successfully ‚úÖ\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Personalized Prediction Function\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def predict_h1b(input_df):\n",
        "    input_df = pd.get_dummies(input_df)\n",
        "    input_df = input_df.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    prob = model.predict_proba(input_df)[:,1][0]\n",
        "    prediction = 1 if prob >= best_threshold else 0\n",
        "\n",
        "    return {\n",
        "        \"Probability_Certified\": round(float(prob), 4),\n",
        "        \"Prediction\": \"Certified\" if prediction == 1 else \"Denied\"\n",
        "    }\n",
        "\n",
        "print(\"\\nPipeline ready for deployment üéØ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBFvJ9tKBkoO",
        "outputId": "453367f2-38ad-45bc-c23c-c6823546ba60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC Score: 0.8940278128477774\n",
            "\n",
            "Best Threshold (Balanced): 0.4000000000000001\n",
            "Best Macro F1: 0.8021462856870616\n",
            "\n",
            "Final Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.67      0.78       327\n",
            "           1       0.74      0.94      0.83       327\n",
            "\n",
            "    accuracy                           0.81       654\n",
            "   macro avg       0.83      0.81      0.80       654\n",
            "weighted avg       0.83      0.81      0.80       654\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score\n",
        "\n",
        "# ================================\n",
        "# GET PROBABILITIES\n",
        "# ================================\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# ================================\n",
        "# FIND BEST BALANCED THRESHOLD\n",
        "# ================================\n",
        "\n",
        "thresholds = np.arange(0.05, 0.95, 0.01)\n",
        "\n",
        "best_threshold = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_temp = (y_prob >= t).astype(int)\n",
        "    score = f1_score(y_test, y_pred_temp, average='macro')  # balanced F1\n",
        "\n",
        "    if score > best_f1:\n",
        "        best_f1 = score\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"\\nBest Threshold (Balanced):\", best_threshold)\n",
        "print(\"Best Macro F1:\", best_f1)\n",
        "\n",
        "# ================================\n",
        "# FINAL PREDICTIONS USING BEST THRESHOLD\n",
        "# ================================\n",
        "\n",
        "y_pred_final = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\nFinal Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A81Qt8NED79v",
        "outputId": "0b3cada4-1d9f-4bbb-bb20-9ffd059322ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leakage check ‚Üí CASE_STATUS in X?: False\n",
            "Categorical columns: Index(['JOB_TITLE', 'SOC_CODE', 'SOC_TITLE', 'FULL_TIME_POSITION',\n",
            "       'WAGE_UNIT_OF_PAY', 'WORKSITE_STATE', 'EMPLOYER_NAME', 'SUPPORT_H1B'],\n",
            "      dtype='object')\n",
            "Encoding completed ‚úÖ\n",
            "Shape after encoding: (3266, 4265)\n",
            "Model trained successfully üöÄ\n",
            "ROC-AUC Score: 0.8925689008594488\n",
            "\n",
            "Final Classification Report (Threshold = 0.40):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.64      0.76       327\n",
            "           1       0.73      0.95      0.82       327\n",
            "\n",
            "    accuracy                           0.80       654\n",
            "   macro avg       0.83      0.80      0.79       654\n",
            "weighted avg       0.83      0.80      0.79       654\n",
            "\n",
            "Model saved successfully ‚úÖ\n",
            "\n",
            "Pipeline ready for deployment üéØ\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# H1B APPROVAL PREDICTION MODEL ‚Äì FINAL VERSION\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ PREPARE FEATURES & TARGET\n",
        "# ============================================================\n",
        "\n",
        "# Target already created as TARGET (1 = Certified, 0 = Denied)\n",
        "\n",
        "# Drop leakage column\n",
        "X = balanced_df.drop(columns=['TARGET', 'CASE_STATUS'], errors='ignore')\n",
        "y = balanced_df['TARGET']\n",
        "\n",
        "print(\"Leakage check ‚Üí CASE_STATUS in X?:\", 'CASE_STATUS' in X.columns)\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ ENCODE CATEGORICAL FEATURES\n",
        "# ============================================================\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Clean column names (XGBoost safe)\n",
        "X.columns = X.columns.str.replace('[', '', regex=False)\n",
        "X.columns = X.columns.str.replace(']', '', regex=False)\n",
        "X.columns = X.columns.str.replace('<', '', regex=False)\n",
        "\n",
        "print(\"Encoding completed ‚úÖ\")\n",
        "print(\"Shape after encoding:\", X.shape)\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ TRAIN TEST SPLIT\n",
        "# ============================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ TRAIN XGBOOST MODEL\n",
        "# ============================================================\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully üöÄ\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ EVALUATE ROC-AUC\n",
        "# ============================================================\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ USE YOUR OPTIMIZED THRESHOLD\n",
        "# ============================================================\n",
        "\n",
        "FINAL_THRESHOLD = 0.40\n",
        "\n",
        "y_pred_final = (y_prob >= FINAL_THRESHOLD).astype(int)\n",
        "\n",
        "print(\"\\nFinal Classification Report (Threshold = 0.40):\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ SAVE MODEL\n",
        "# ============================================================\n",
        "\n",
        "joblib.dump(model, \"h1b_model_final.pkl\")\n",
        "print(\"Model saved successfully ‚úÖ\")\n",
        "\n",
        "# ============================================================\n",
        "# 8Ô∏è‚É£ USER PREDICTION FUNCTION (PERSONALIZED)\n",
        "# ============================================================\n",
        "\n",
        "def predict_user(user_input_dict):\n",
        "\n",
        "    user_df = pd.DataFrame([user_input_dict])\n",
        "\n",
        "    # Encode same way\n",
        "    user_df = pd.get_dummies(user_df)\n",
        "\n",
        "    # Align columns with training data\n",
        "    user_df = user_df.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    prob = model.predict_proba(user_df)[:, 1][0]\n",
        "    prediction = 1 if prob >= FINAL_THRESHOLD else 0\n",
        "\n",
        "    return {\n",
        "        \"Probability_Certified\": round(float(prob), 4),\n",
        "        \"Prediction\": \"Certified\" if prediction == 1 else \"Denied\"\n",
        "    }\n",
        "\n",
        "print(\"\\nPipeline ready for deployment üéØ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNlUWS2SnTBj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}